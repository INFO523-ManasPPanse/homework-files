{
  "hash": "3111dced9ccb4d0658411a85658c3b8e",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Regression Models\"\nauthor:\n  - name: \"Manas P Panse\"\n    affiliation: \"College of Information Science, University of Arizona\"\nformat:\n   html:\n    code-tools: true\n    code-overflow: wrap\n    embed-resources: true\ncode-annotations: hover\nexecute:\n  warning: false\n  messae: false\n  error: false\ntoc: true\n---\n\n# 0 - Pre-Checks\n\n::: {#python-version .cell execution_count=1}\n``` {.python .cell-code}\n# Checking Python Version\n\n!python --version\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nPython 3.12.3\n```\n:::\n:::\n\n\n::: {#import-libraries .cell execution_count=2}\n``` {.python .cell-code}\n# Importing Necessary Libraries\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.linear_model import LassoCV\nfrom sklearn.linear_model import RidgeCV\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nimport statsmodels.api as sm\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\n\n\nsns.set(style = \"white\")\n```\n:::\n\n\n::: {#import-dataset .cell execution_count=3}\n``` {.python .cell-code}\n# Importing Dataset\n\nsurvival_df = pd.read_csv(\"data/hw-04/survivalists.csv\")\n```\n:::\n\n\n# 1 - Data Preparation and Exploration\n\n## Task 1 - Exploratory Data Analysis (1 Cr.)\n\n### Data Overview\n\n::: {#eda .cell execution_count=4}\n``` {.python .cell-code}\nsurvival_df.info()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 94 entries, 0 to 93\nData columns (total 16 columns):\n #   Column               Non-Null Count  Dtype  \n---  ------               --------------  -----  \n 0   season               94 non-null     int64  \n 1   name                 94 non-null     object \n 2   age                  94 non-null     int64  \n 3   gender               94 non-null     object \n 4   city                 94 non-null     object \n 5   state                93 non-null     object \n 6   country              94 non-null     object \n 7   result               94 non-null     int64  \n 8   days_lasted          94 non-null     int64  \n 9   medically_evacuated  94 non-null     bool   \n 10  reason_tapped_out    84 non-null     object \n 11  reason_category      84 non-null     object \n 12  team                 14 non-null     object \n 13  day_linked_up        8 non-null      float64\n 14  profession           94 non-null     object \n 15  url                  94 non-null     object \ndtypes: bool(1), float64(1), int64(4), object(10)\nmemory usage: 11.2+ KB\n```\n:::\n:::\n\n\n#### Shape\n\nThe dataset contains **94** ROWS and **16** COLUMNS.\n\n#### Columns\n\n1.  Categorical Columns : `name`, `gender`, `city`, `state`, `country`, `medically_evacuated`, `reason_tapped_out`, `reason_category`, `team`, `profession`, & `url`.\n2.  Numerical Columns : `season`, `age`, `result`, `days_lasted`, & `day_linked_up`.\n\n\\[Going to include the `bool` as a categoric value.\\]\n\n#### DataTypes\n\n1.  `int64` : 04 column.\n2.  `object` : 10 columns.\n3.  `bool` : 01 column.\n4.  `float64` : 01 columns.\n\n### Descriptive Statistics\n\n::: {#cell-eda-desc-stats .cell execution_count=5}\n``` {.python .cell-code}\nsurvival_df.describe()\n```\n\n::: {#eda-desc-stats .cell-output .cell-output-display execution_count=5}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>season</th>\n      <th>age</th>\n      <th>result</th>\n      <th>days_lasted</th>\n      <th>day_linked_up</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>94.000000</td>\n      <td>94.00000</td>\n      <td>94.000000</td>\n      <td>94.000000</td>\n      <td>8.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>4.957447</td>\n      <td>37.93617</td>\n      <td>5.276596</td>\n      <td>39.042553</td>\n      <td>9.000000</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>2.548096</td>\n      <td>8.84491</td>\n      <td>2.826161</td>\n      <td>27.849409</td>\n      <td>0.755929</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.000000</td>\n      <td>19.00000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>8.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>3.000000</td>\n      <td>31.00000</td>\n      <td>3.000000</td>\n      <td>10.500000</td>\n      <td>8.750000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>5.000000</td>\n      <td>38.50000</td>\n      <td>5.000000</td>\n      <td>39.500000</td>\n      <td>9.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>7.000000</td>\n      <td>44.00000</td>\n      <td>7.750000</td>\n      <td>63.750000</td>\n      <td>9.250000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>9.000000</td>\n      <td>61.00000</td>\n      <td>10.000000</td>\n      <td>100.000000</td>\n      <td>10.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n### Column Separations for Future Use\n\n::: {#eda-column-separate .cell execution_count=6}\n``` {.python .cell-code}\n# Numerical Columns\nnumeric_cols = survival_df.select_dtypes(include = ['int64', 'float64']).columns\n\n# Categorical Columns\ncategoric_cols = survival_df.select_dtypes(include = ['object', 'bool']).columns\n```\n:::\n\n\n### Distribution of `days_lasted`\n\n::: {#cell-distro-days-lasted .cell execution_count=7}\n``` {.python .cell-code}\nplt.figure(figsize = (8, 6))\ndl = sns.histplot(survival_df['days_lasted'], kde = True, bins = 20, color = 'lime')\ndl.lines[0].set_color('red')\nplt.title('Distribution of Days Lasted')\nplt.xlabel('Days Lasted')\nplt.ylabel('Frequency')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](hw-04-manasppanse_files/figure-html/distro-days-lasted-output-1.png){#distro-days-lasted width=663 height=529}\n:::\n:::\n\n\n### Relationship between ...\n\n### `gender` vs `days_lasted`\n\n::: {#cell-gender-days-lasted .cell execution_count=8}\n``` {.python .cell-code}\nplt.figure(figsize = (8, 6))\nsns.boxplot(data = survival_df, x = 'gender', y = 'days_lasted', palette = 'bright')\nplt.title('Days Lasted vs Gender')\nplt.xlabel('Gender')\nplt.ylabel('Days Lasted')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](hw-04-manasppanse_files/figure-html/gender-days-lasted-output-1.png){#gender-days-lasted width=671 height=529}\n:::\n:::\n\n\n### `age` vs `days_lasted`\n\n::: {#cell-age-days-lasted .cell execution_count=9}\n``` {.python .cell-code}\nage_bins = pd.cut(survival_df['age'], bins = [20, 30, 40, 50, 60, 70], labels = [\"20-30\", \"30-40\", \"40-50\", \"50-60\", \"60-70\"])\n\nplt.figure(figsize = (8, 6))\nsns.boxplot(x = age_bins, y = survival_df['days_lasted'], palette = 'bright')\n# sns.boxplot(x = age_bins, y = survival_df['days_lasted'], palette = 'Paired')\nplt.title('Days Lasted vs Age Group')\nplt.xlabel('Age Group')\nplt.ylabel('Days Lasted')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](hw-04-manasppanse_files/figure-html/age-days-lasted-output-1.png){#age-days-lasted width=671 height=529}\n:::\n:::\n\n\n# 2 - Data Preprocessing\n\n## Task 2 - Data Cleaning (1 Cr.)\n\n### Handling Missing Values\n\n::: {#cell-pre-check-missing-values .cell execution_count=10}\n``` {.python .cell-code}\nsurvival_df.isnull().sum()\n```\n\n::: {#pre-check-missing-values .cell-output .cell-output-display execution_count=10}\n```\nseason                  0\nname                    0\nage                     0\ngender                  0\ncity                    0\nstate                   1\ncountry                 0\nresult                  0\ndays_lasted             0\nmedically_evacuated     0\nreason_tapped_out      10\nreason_category        10\nteam                   80\nday_linked_up          86\nprofession              0\nurl                     0\ndtype: int64\n```\n:::\n:::\n\n\n::: {#correct-missing-values .cell execution_count=11}\n``` {.python .cell-code}\nfor col in survival_df.select_dtypes(include = ['int64', 'float64']):\n    survival_df[col].fillna(survival_df[col].median(), inplace = True)\n\nfor col in survival_df.select_dtypes(include = ['object', 'bool']):\n    survival_df[col].fillna(survival_df[col].mode()[0], inplace = True)\n```\n:::\n\n\n::: {#cell-check-missing-values .cell execution_count=12}\n``` {.python .cell-code}\nsurvival_df.isnull().sum()\n```\n\n::: {#check-missing-values .cell-output .cell-output-display execution_count=12}\n```\nseason                 0\nname                   0\nage                    0\ngender                 0\ncity                   0\nstate                  0\ncountry                0\nresult                 0\ndays_lasted            0\nmedically_evacuated    0\nreason_tapped_out      0\nreason_category        0\nteam                   0\nday_linked_up          0\nprofession             0\nurl                    0\ndtype: int64\n```\n:::\n:::\n\n\n### Removing Outliers\n\n::: {#outlier-removal .cell execution_count=13}\n``` {.python .cell-code}\n# Calculate IQR for 'days_lasted'\nQ1 = survival_df['days_lasted'].quantile(0.25)\nQ3 = survival_df['days_lasted'].quantile(0.75)\nIQR = Q3 - Q1\n\n# Calculate bounds for detecting outliers\nlower_bound = Q1 - 1.5 * IQR\nupper_bound = Q3 + 1.5 * IQR\n\n# Filter out outliers\nclean_survival_df = survival_df[(survival_df['days_lasted'] >= lower_bound) & (survival_df['days_lasted'] <= upper_bound)]\n\n# Check how many rows were removed\nprint(f\"Before Rows : {len(survival_df)}\")\nprint(f\"Afterr Rows : {len(clean_survival_df)}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nBefore Rows : 94\nAfterr Rows : 94\n```\n:::\n:::\n\n\n## Task 3 - Data Transformation (1 Cr.)\n\n### Feature Scaling\n\n::: {#cell-zscore-feature-scale .cell execution_count=14}\n``` {.python .cell-code}\nscaler = StandardScaler()\n\nsurvival_df[['age', 'days_lasted']] = scaler.fit_transform(survival_df[['age', 'days_lasted']])\n\nsurvival_df[['age', 'days_lasted']].describe()\n```\n\n::: {#zscore-feature-scale .cell-output .cell-output-display execution_count=14}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>days_lasted</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>9.400000e+01</td>\n      <td>9.400000e+01</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>-8.976271e-17</td>\n      <td>2.480285e-17</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>1.005362e+00</td>\n      <td>1.005362e+00</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>-2.152391e+00</td>\n      <td>-1.409434e+00</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>-7.884039e-01</td>\n      <td>-1.030384e+00</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>6.408805e-02</td>\n      <td>1.651380e-02</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>6.892488e-01</td>\n      <td>8.919373e-01</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>2.621564e+00</td>\n      <td>2.200560e+00</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n### Variable Transformation\n\n::: {#cell-variable-transform .cell execution_count=15}\n``` {.python .cell-code}\nclean_survival_df['days_lasted_log'] = np.log1p(clean_survival_df['days_lasted'] + 1)\n\nclean_survival_df[['days_lasted', 'days_lasted_log']].head()\n```\n\n::: {#variable-transform .cell-output .cell-output-display execution_count=15}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>days_lasted</th>\n      <th>days_lasted_log</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>56</td>\n      <td>4.060443</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>55</td>\n      <td>4.043051</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>43</td>\n      <td>3.806662</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>39</td>\n      <td>3.713572</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>8</td>\n      <td>2.302585</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n### Histogram of `days_lasted_log`\n\n::: {#cell-histogram-days-lasted-log .cell execution_count=16}\n``` {.python .cell-code}\nplt.figure(figsize = (8, 6))\ndll = sns.histplot(clean_survival_df['days_lasted_log'], kde = True, bins = 20, color = 'lime')\ndll.lines[0].set_color('red')\nplt.title('Distribution of Log - Transformed Days Lasted')\nplt.xlabel('Log of Days Lasted')\nplt.ylabel('Frequency')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](hw-04-manasppanse_files/figure-html/histogram-days-lasted-log-output-1.png){#histogram-days-lasted-log width=676 height=529}\n:::\n:::\n\n\n### The Remaining Processing Steps\n\n::: {#given-processing-steps .cell execution_count=17}\n``` {.python .cell-code}\n# Drop irrelevant columns\nsurvivalistsRed = clean_survival_df.drop(['name', 'city', 'url', 'profession', 'reason_tapped_out', 'state', 'country', 'reason_category', 'team', 'days_lasted'], axis = 1)\n\n# Label encoding for 'gender'\nsurvivalistsFinal = pd.get_dummies(survivalistsRed, columns = ['gender'], drop_first = True)\n\nsurvivalistsFinal['medically_evacuated'] = survivalistsFinal['medically_evacuated'].astype(int)\nsurvivalistsFinal['gender_Male'] = survivalistsFinal['gender_Male'].astype(int)\n\nsurvivalistsFinal.info()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 94 entries, 0 to 93\nData columns (total 7 columns):\n #   Column               Non-Null Count  Dtype  \n---  ------               --------------  -----  \n 0   season               94 non-null     int64  \n 1   age                  94 non-null     int64  \n 2   result               94 non-null     int64  \n 3   medically_evacuated  94 non-null     int32  \n 4   day_linked_up        94 non-null     float64\n 5   days_lasted_log      94 non-null     float64\n 6   gender_Male          94 non-null     int32  \ndtypes: float64(2), int32(2), int64(3)\nmemory usage: 4.5 KB\n```\n:::\n:::\n\n\n# 3 - Ordinary Least Squares (OLS) Regression\n\n## Model Building (1 Cr.)\n\n::: {#cell-model-building .cell execution_count=18}\n``` {.python .cell-code}\nx = survivalistsFinal.drop('days_lasted_log', axis = 1)\ny = survivalistsFinal['days_lasted_log']\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 42)\nx_train_const = sm.add_constant(x_train)\n\nols_model = sm.OLS(y_train, x_train_const).fit()\nols_model.summary()\n\n# NO IDEA WHY IT SHOWS THE TITLE 'OLS Regression Results' AFTER HALF OF THE RESULT !!!\n```\n\n::: {#model-building .cell-output .cell-output-display execution_count=18}\n```{=html}\n<table class=\"simpletable\">\n<caption>OLS Regression Results</caption>\n<tr>\n  <th>Dep. Variable:</th>     <td>days_lasted_log</td> <th>  R-squared:         </th> <td>   0.715</td>\n</tr>\n<tr>\n  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.689</td>\n</tr>\n<tr>\n  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   28.38</td>\n</tr>\n<tr>\n  <th>Date:</th>             <td>Fri, 01 Nov 2024</td> <th>  Prob (F-statistic):</th> <td>1.01e-16</td>\n</tr>\n<tr>\n  <th>Time:</th>                 <td>21:14:44</td>     <th>  Log-Likelihood:    </th> <td> -60.591</td>\n</tr>\n<tr>\n  <th>No. Observations:</th>      <td>    75</td>      <th>  AIC:               </th> <td>   135.2</td>\n</tr>\n<tr>\n  <th>Df Residuals:</th>          <td>    68</td>      <th>  BIC:               </th> <td>   151.4</td>\n</tr>\n<tr>\n  <th>Df Model:</th>              <td>     6</td>      <th>                     </th>     <td> </td>   \n</tr>\n<tr>\n  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n</tr>\n</table>\n<table class=\"simpletable\">\n<tr>\n           <td></td>              <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n</tr>\n<tr>\n  <th>const</th>               <td>    0.2251</td> <td>    2.650</td> <td>    0.085</td> <td> 0.933</td> <td>   -5.063</td> <td>    5.513</td>\n</tr>\n<tr>\n  <th>season</th>              <td>    0.1166</td> <td>    0.026</td> <td>    4.426</td> <td> 0.000</td> <td>    0.064</td> <td>    0.169</td>\n</tr>\n<tr>\n  <th>age</th>                 <td>    0.0122</td> <td>    0.007</td> <td>    1.649</td> <td> 0.104</td> <td>   -0.003</td> <td>    0.027</td>\n</tr>\n<tr>\n  <th>result</th>              <td>   -0.2645</td> <td>    0.024</td> <td>  -10.876</td> <td> 0.000</td> <td>   -0.313</td> <td>   -0.216</td>\n</tr>\n<tr>\n  <th>medically_evacuated</th> <td>   -0.2290</td> <td>    0.167</td> <td>   -1.373</td> <td> 0.174</td> <td>   -0.562</td> <td>    0.104</td>\n</tr>\n<tr>\n  <th>day_linked_up</th>       <td>    0.4193</td> <td>    0.288</td> <td>    1.456</td> <td> 0.150</td> <td>   -0.155</td> <td>    0.994</td>\n</tr>\n<tr>\n  <th>gender_Male</th>         <td>   -0.3012</td> <td>    0.175</td> <td>   -1.717</td> <td> 0.091</td> <td>   -0.651</td> <td>    0.049</td>\n</tr>\n</table>\n<table class=\"simpletable\">\n<tr>\n  <th>Omnibus:</th>       <td> 2.326</td> <th>  Durbin-Watson:     </th> <td>   1.878</td>\n</tr>\n<tr>\n  <th>Prob(Omnibus):</th> <td> 0.313</td> <th>  Jarque-Bera (JB):  </th> <td>   2.035</td>\n</tr>\n<tr>\n  <th>Skew:</th>          <td>-0.403</td> <th>  Prob(JB):          </th> <td>   0.361</td>\n</tr>\n<tr>\n  <th>Kurtosis:</th>      <td> 2.962</td> <th>  Cond. No.          </th> <td>1.65e+03</td>\n</tr>\n</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.65e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems.\n```\n:::\n:::\n\n\nInterpretation -\n\n1.  `season` & `result` are the most significant predictors. Later seasons increase the number of days lasted, while worse results decrease the number of days.\n\n2.  `gender` shows some negative effect, which does suggest that *The Boys* may last fewer days, but the result isn't that robust (statistically).\n\n3.  `age`, `medically_evaluated`, and `days_linked_up` show some effects.\n\n### Model Training and Evaluation (2 Cr.)\n\n::: {#model-train-eval .cell execution_count=19}\n``` {.python .cell-code}\nx_test_const = sm.add_constant(x_test)\nx_test_const = x_test_const.reindex(columns = x_train_const.columns, fill_value = 0)\ny_pred = ols_model.predict(x_test_const)\n\nmse = mean_squared_error(y_test, y_pred)\nprint(f\"Mean Squared Error : {mse}\")\n\nr_squared = r2_score(y_test, y_pred)\nprint(f\"R-Squared : {r_squared}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nMean Squared Error : 0.47915396259842913\nR-Squared : 0.5011470534295956\n```\n:::\n:::\n\n\nInterpretation -\n\n1.  MSE : **0.479**. This metric basically represents the average sq. difference between actual and predicted values. The lower this value, the better. In our case, there are still some errors in the predictions, although it might be a reasonable one given the log transformed scale of our `days_lasted_log`.\n\n2.  R-Squared : **0.501**. This metric basically explains how much was explained by the model. The higher this value, the better. In our case, our model captures half of the variability in the outcome based on the predictors.\n\n## Task 6 - Residual Plots (1 Cr.)\n\n::: {#residual-calc .cell execution_count=20}\n``` {.python .cell-code}\nresiduals = y_test - y_pred\n```\n:::\n\n\n::: {#cell-residual-plot .cell execution_count=21}\n``` {.python .cell-code}\nplt.figure(figsize = (8, 6))\nplt.scatter(y_pred, residuals, color = \"lime\")\nplt.axhline(y = 0, color = 'red', linestyle = '--')\nplt.title('Residual Plot')\nplt.xlabel('Predicted Values')\nplt.ylabel('Residuals')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](hw-04-manasppanse_files/figure-html/residual-plot-output-1.png){#residual-plot width=676 height=529}\n:::\n:::\n\n\n## Task 7 - Normality of Residuals (1 Cr.)\n\n::: {#cell-residual-norm-qqplot .cell execution_count=22}\n``` {.python .cell-code}\nresiduals_train = ols_model.resid\n\nsm.qqplot(residuals_train, line = '45', fit = True)\nplt.title('Q - Q Plot of Residuals')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](hw-04-manasppanse_files/figure-html/residual-norm-qqplot-output-1.png){#residual-norm-qqplot width=589 height=455}\n:::\n:::\n\n\n# 4 - Alternative Regressions\n\n### Feature Scaling\n\n::: {#prerun-code .cell execution_count=23}\n``` {.python .cell-code}\nx_train_scaled = scaler.fit_transform(x_train)\nx_test_scaled = scaler.transform(x_test)\n```\n:::\n\n\n::: {#alpha-values .cell execution_count=24}\n``` {.python .cell-code}\n# Defining Alpha Values\nalphas = [0.01, 0.1, 1, 10, 100]\n```\n:::\n\n\n## Task 8 - Ridge Regression (2 Cr.)\n\n::: {#ridge-regression .cell execution_count=25}\n``` {.python .cell-code}\nridge_cv = RidgeCV(alphas = alphas, store_cv_values = True)\nridge_cv.fit(x_train_scaled, y_train)\nbest_alpha_ridge = ridge_cv.alpha_\n\ny_pred_ridge = ridge_cv.predict(x_test_scaled)\nmse_ridge = mean_squared_error(y_test, y_pred_ridge)\nr2_ridge = r2_score(y_test, y_pred_ridge)\n\nprint(f\"Best λ (alpha)     : {best_alpha_ridge}\")\nprint(f\"Mean Squared Error : {mse_ridge}\")\nprint(f\"R-Squared          : {r2_ridge}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nBest λ (alpha)     : 1.0\nMean Squared Error : 0.43606391143638773\nR-Squared          : 0.5460086233381156\n```\n:::\n:::\n\n\n## OPT Task - Lasso Regression\n\n::: {#lasso-regression .cell execution_count=26}\n``` {.python .cell-code}\nlasso_cv = LassoCV(alphas = alphas, cv = 5)\nlasso_cv.fit(x_train_scaled, y_train)\nbest_alpha_lasso = lasso_cv.alpha_\n\ny_pred_lasso = lasso_cv.predict(x_test_scaled)\nmse_lasso = mean_squared_error(y_test, y_pred_lasso)\nr2_lasso = r2_score(y_test, y_pred_lasso)\n\nprint(f\"Best λ (alpha)     : {best_alpha_lasso}\")\nprint(f\"Mean Squared Error : {mse_lasso}\")\nprint(f\"R-Squared          : {r2_lasso}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nBest λ (alpha)     : 0.1\nMean Squared Error : 0.4323847164869538\nR-Squared          : 0.5498390773983908\n```\n:::\n:::\n\n\n# 5 - Declaration of Independent Work\n\nSee **HOMEPAGE** for details\n\n",
    "supporting": [
      "hw-04-manasppanse_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}